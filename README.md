# -Challenge-Alura-Telecom-X_2

# ğŸ“¡ Telecom X â€“ Modelo de PrevisÃ£o de Churn (Parte 2)

ğŸ¯ **Objetivo do Projeto**  
Esta segunda fase do projeto tem como objetivo desenvolver e comparar modelos de Machine Learning para prever a evasÃ£o de clientes (*churn*) da Telecom X. A partir da anÃ¡lise exploratÃ³ria realizada na Parte 1, construÃ­mos pipelines de classificaÃ§Ã£o, avaliamos diferentes algoritmos e identificamos o modelo com melhor capacidade preditiva, fornecendo uma ferramenta para a equipe de CiÃªncia de Dados priorizar aÃ§Ãµes de retenÃ§Ã£o.

ğŸ› ï¸ **Tecnologias e Bibliotecas**  

- **Linguagem:** Python 3  
- **ManipulaÃ§Ã£o de Dados:** Pandas, NumPy  
- **PrÃ©-processamento e Modelagem:** Scikit-learn (Pipelines, StandardScaler, OneHotEncoder, RandomForest, LogisticRegression)  
- **Modelo AvanÃ§ado:** XGBoost  
- **VisualizaÃ§Ã£o:** Matplotlib, Seaborn  
- **PersistÃªncia:** Joblib  
- **Formato de Entrega:** Jupyter Notebook (`TelecomX_Modelo_Final.ipynb`)

ğŸš€ **Estrutura do Projeto (Modelagem)**  

A modelagem seguiu uma abordagem estruturada e reprodutÃ­vel:

1. **PreparaÃ§Ã£o dos Dados**  
   - Carregamento e limpeza (mesmos passos da Parte 1).  
   - TransformaÃ§Ã£o de variÃ¡veis categÃ³ricas com One-Hot Encoding.  
   - PadronizaÃ§Ã£o de variÃ¡veis numÃ©ricas.

2. **SeleÃ§Ã£o de VariÃ¡veis**  
   - AnÃ¡lise de correlaÃ§Ã£o para variÃ¡veis numÃ©ricas.  
   - Teste Quiâ€‘Quadrado para variÃ¡veis categÃ³ricas.  
   - ConsolidaÃ§Ã£o das features mais relevantes.

3. **Treinamento de MÃºltiplos Modelos**  
   - **Random Forest** (com balanceamento de classes).  
   - **RegressÃ£o LogÃ­stica** (com balanceamento).  
   - **XGBoost** (com ajuste de `scale_pos_weight` para desbalanceamento).

4. **AvaliaÃ§Ã£o e ComparaÃ§Ã£o**  
   - RelatÃ³rios de classificaÃ§Ã£o (Precision, Recall, F1).  
   - Matrizes de confusÃ£o.  
   - Curvas ROC e AUC.  
   - Tabela comparativa de desempenho.

5. **AnÃ¡lise de ImportÃ¢ncia de VariÃ¡veis**  
   - ImportÃ¢ncia para modelos baseados em Ã¡rvores.  
   - Coeficientes da RegressÃ£o LogÃ­stica.

6. **Salvando o Melhor Modelo**  
   - O modelo com maior AUC-ROC Ã© persistido em formato `.pkl` para uso em produÃ§Ã£o.

ğŸ’¡ **Principais Insights da Modelagem**  

- O **XGBoost** apresentou o melhor desempenho geral, com AUC-ROC acima de 0,85, superando Random Forest e RegressÃ£o LogÃ­stica.  
- As variÃ¡veis mais importantes para a prediÃ§Ã£o foram:  
  - **Tempo de contrato (tenure)**  
  - **Tipo de contrato (mensal vs. anual)**  
  - **CobranÃ§a mensal (monthly_charges)**  
  - **ServiÃ§os contratados** (ex.: seguranÃ§a online, suporte tÃ©cnico)  
- Clientes com contratos de curto prazo e faturas elevadas sÃ£o os que apresentam maior probabilidade de churn, corroborando os achados da EDA.

ğŸ“ˆ **Resultados dos Modelos**  

| Modelo               | AcurÃ¡cia | Precision (Churn) | Recall (Churn) | F1 (Churn) | AUC-ROC |
|----------------------|----------|-------------------|----------------|------------|---------|
| **XGBoost**          | 0,80     | 0,68              | 0,55           | 0,61       | **0,86**|
| Random Forest        | 0,79     | 0,65              | 0,54           | 0,59       | 0,84    |
| RegressÃ£o LogÃ­stica  | 0,79     | 0,62              | 0,60           | 0,61       | 0,85    |

> *Nota: Os valores podem variar ligeiramente conforme a semente aleatÃ³ria.*

ğŸ“ **Como Executar**  

1. Certifique-se de ter o arquivo `TelecomX_Data.json` no mesmo diretÃ³rio do notebook.  
2. Instale as dependÃªncias necessÃ¡rias:  
   ```bash
   pip install pandas numpy scikit-learn joblib matplotlib seaborn xgboost
Abra o notebook TelecomX_Modelo_Final.ipynb em um ambiente Jupyter (JupyterLab, VS Code, Google Colab).

Execute todas as cÃ©lulas sequencialmente.
